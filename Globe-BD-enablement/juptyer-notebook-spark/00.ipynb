{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Configuration of Spark 1.6.2 (Windows)\n",
    "Setting Up On A Stand Alone Machine\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation for Windows\n",
    "---\n",
    "Download Apache Spark 1.6.2 tar file from [here](https://spark.apache.org/downloads.html). Verify you are downloading the version pre-built for Hadoop 2.6.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/spark_download.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the contents of this .tgz file into the following directory structure - "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mkdir DRIVE:\\Globe\\spark\\1.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/spark_windows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Scala 2.10.5 and install from [here](http://www.scala-lang.org/download/2.10.5.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/download-scala.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download winutils.exe\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the critical point for me, because I downloaded one version and did not work until I realized that there are 64-bits and 32-bits versions of this file. Here you can find them accordingly:\n",
    "\n",
    "[32-bit winutils.exe](#)\n",
    "\n",
    "[64-bit winutils.exe](#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Variables Configuration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>_JAVA_OPTION</b>: I set this variable to the value showed in the figure below. I was getting Java Heap Memory problems with the default values and this fixed this problem.\n",
    "- <b>HADOOP_HOME</b>: even when Spark can run without Hadoop, the version I downloaded is prebuilt for Hadoop 2.6 and looks in the code for it. To fix this inconvenient I set this variable to the folder containing the winutils.exe file\n",
    "- <b>JAVA_HOME</b>: usually you already set this variable when you install java but it is better to verify that exist and is correct.\n",
    "- <b>SCALA_HOME</b>: the bin folder of the Scala location. If you use the standard location from the installer should be the path in the figure below\n",
    "- <b>SPARK_HOME</b>: the bin folder path of where you uncompressed Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/env-variables-1.jpg)\n",
    "![caption](files/env-variables-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if Scala is up and runnning by issuing the following command - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/scala_version_windows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the spark-shell command line to see if Spark is running correctly - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/spark-shell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the PATH VARIABLES and winutils.exe is not installed correctly, you will receive the following errors -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/spark_error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For latest Spark releases, if you get the permission error for /tmp/hive directory as given below:\n",
    "The root scratch dir: <b>/tmp/hive</b> on HDFS should be writable. Current permissions are: rw-rw-rw- Open a command prompt as <b>administrator</b> and type - "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "C:\\Globe\\spark>D:\\winutils\\bin\\winutils.exe chmod 777 C:\\tmp\\hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/chmod-7771.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Spark UI : open http://localhost:4040/ in browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Spark Shell\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the same command prompt go to the Spark folder and type the following command to run the Scala shell -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/start-the-spark-shell.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Clear the last line in Scala is CTRL-L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Scala\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting via command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/scala_hello_world.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting via submitted scripts. Create a directory for Scala code.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mkdir /usr/Local/Cellar/spark/code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vi /usr/Local/Cellar/spark/code/HelloWorld.scala"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "object HelloWorld {\n",
    "   /* This is my first java program.  \n",
    "   * This will print 'Hello World' as the output\n",
    "   */\n",
    "   def main(args: Array[String]) {\n",
    "      println(\"Hello, world!\") // prints Hello World\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot change directories per se within the Scala shell however you can do the following -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scala> System.getProperty(\"user.dir\")\n",
    "res9: String = /usr/local/Cellar/spark/1.6.2\n",
    "\n",
    "scala> System.setProperty(\"user.dir\",\"/usr/local/Cellar/spark/code\")\n",
    "res10: String = /usr/local/Cellar/spark/1.6.2\n",
    "\n",
    "scala> System.getProperty(\"user.dir\")\n",
    "res11: String = /usr/local/Cellar/spark/code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit and compile Scala code via terminal. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " scalac HelloWorld.scala\n",
    " scala HelloWorld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/scala_compile.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
