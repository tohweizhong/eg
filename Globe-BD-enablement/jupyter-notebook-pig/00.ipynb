{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is Apache Pig?</b><br><br>\n",
    "Apache Pig is an abstraction over MapReduce. It is a tool/platform which is used to analyze larger sets of data representing them as data flows. Pig is generally used with Hadoop; we can perform all the data manipulation operations in Hadoop using Apache Pig.\n",
    "\n",
    "To write data analysis programs, Pig provides a high-level language known as Pig Latin. This language provides various operators using which programmers can develop their own functions for reading, writing, and processing data.\n",
    "\n",
    "To analyze data using Apache Pig, programmers need to write scripts using Pig Latin language. All these scripts are internally converted to Map and Reduce tasks. Apache Pig has a component known as Pig Engine that accepts the Pig Latin scripts as input and converts those scripts into MapReduce jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features of Pig\n",
    "---\n",
    "Apache Pig comes with the following features −\n",
    "\n",
    "- Rich set of operators − It provides many operators to perform operations like join, sort, filer, etc.\n",
    "\n",
    "- Ease of programming − Pig Latin is similar to SQL and it is easy to write a Pig script if you are good at SQL.\n",
    "\n",
    "- Optimization opportunities − The tasks in Apache Pig optimize their execution automatically, so the programmers need to focus only on semantics of the language.\n",
    "\n",
    "- Extensibility − Using the existing operators, users can develop their own functions to read, process, and write data.\n",
    "\n",
    "- UDF’s − Pig provides the facility to create User-defined Functions in other programming languages such as Java and invoke or embed them in Pig Scripts.\n",
    "\n",
    "- Handles all kinds of data − Apache Pig analyzes all kinds of data, both structured as well as unstructured. It stores the results in HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Pig Versus MapReduce\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "<tr>\n",
    "<th style=\"text-align:center;\">Apache Pig</th>\n",
    "<th style=\"text-align:center;\">MapReduce</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Apache Pig is a data flow language.</td>\n",
    "<td>MapReduce is a data processing paradigm.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>It is a high level language.</td>\n",
    "<td>MapReduce is low level and rigid.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Performing a Join operation in Apache Pig is pretty simple.</td>\n",
    "<td>It is quite difficult in MapReduce to perform a Join operation between datasets.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Any novice programmer with a basic knowledge of SQL can work conveniently with Apache Pig.</td>\n",
    "<td>Exposure to Java is must to work with MapReduce.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Apache Pig uses multi-query approach, thereby reducing the length of the codes to a great extent.</td>\n",
    "<td>MapReduce will require almost 20 times more the number of lines to perform the same task.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>There is no need for compilation. On execution, every Apache Pig operator is converted internally into a MapReduce job.</td>\n",
    "<td>MapReduce jobs have a long compilation process.</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Pig Versus SQL\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "<tr>\n",
    "<th style=\"width:50%;text-align:center;\">Pig</th>\n",
    "<th style=\"width:60%;text-align:center;\">SQL</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Pig Latin is a <b>procedural</b> language.</td>\n",
    "<td>SQL is a <b>declarative</b> language.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>In Apache Pig, <b>schema</b> is optional. We can store data without designing a schema (values are stored as $01, $02 etc.)</td>\n",
    "<td>Schema is mandatory in SQL.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>The data model in Apache Pig is <b>nested relational</b>.</td>\n",
    "<td>The data model used in SQL <b>is flat relational</b>.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Apache Pig provides limited opportunity for <b>Query optimization</b>.</td>\n",
    "<td>There is more opportunity for query optimization in SQL.</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to above differences, Apache Pig Latin −\n",
    "\n",
    "- Allows splits in the pipeline.\n",
    "- Allows developers to store data anywhere in the pipeline.\n",
    "- Declares execution plans.\n",
    "- Provides operators to perform ETL (Extract, Transform, and Load) functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Pig Versus Hive\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Apache Pig and Hive are used to create MapReduce jobs. And in some cases, Hive operates on HDFS in a similar way Apache Pig does. In the following table, we have listed a few significant points that set Apache Pig apart from Hive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "<tr>\n",
    "<th style=\"text-align:center;\">Apache Pig</th>\n",
    "<th style=\"text-align:center;\">Hive</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Apache Pig uses a language called <b>Pig Latin</b>. It was originally created at <b>Yahoo</b>.</td>\n",
    "<td>Hive uses a language called <b>HiveQL</b>. It was originally created at <b>Facebook</b>.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Pig Latin is a data flow language.</td>\n",
    "<td>HiveQL is a query processing language.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Pig Latin is a procedural language and it fits in pipeline paradigm.</td>\n",
    "<td>HiveQL is a declarative language.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Apache Pig can handle structured, unstructured, and semi-structured data.</td>\n",
    "<td>Hive is mostly for structured data.</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History of Apache Pig\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2006, Apache Pig was developed as a research project at Yahoo, especially to create and execute MapReduce jobs on every dataset. In 2007, Apache Pig was open sourced via Apache incubator. In 2008, the first release of Apache Pig came out. In 2010, Apache Pig graduated as an Apache top-level project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he language used to analyze data in Hadoop using Pig is known as Pig Latin. It is a highlevel data processing language which provides a rich set of data types and operators to perform various operations on the data.\n",
    "\n",
    "To perform a particular task Programmers using Pig, programmers need to write a Pig script using the Pig Latin language, and execute them using any of the execution mechanisms (Grunt Shell, UDFs, Embedded). After execution, these scripts will go through a series of transformations applied by the Pig Framework, to produce the desired output.\n",
    "\n",
    "Internally, Apache Pig converts these scripts into a series of MapReduce jobs, and thus, it makes the programmer’s job easy. The architecture of Apache Pig is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/apache_pig_architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Pig Components\n",
    "---\n",
    "As shown in the figure, there are various components in the Apache Pig framework. Let us take a look at the major components.\n",
    "\n",
    "<b>Parser</b><br>\n",
    "Initially the Pig Scripts are handled by the Parser. It checks the syntax of the script, does type checking, and other miscellaneous checks. The output of the parser will be a DAG (directed acyclic graph), which represents the Pig Latin statements and logical operators.\n",
    "\n",
    "In the DAG, the logical operators of the script are represented as the nodes and the data flows are represented as edges.\n",
    "\n",
    "<b>Optimizer</b><br>\n",
    "The logical plan (DAG) is passed to the logical optimizer, which carries out the logical optimizations such as projection and pushdown.\n",
    "\n",
    "<b>Compiler</b><br>\n",
    "The compiler compiles the optimized logical plan into a series of MapReduce jobs.\n",
    "\n",
    "<b>Execution engine</b><br>\n",
    "Finally the MapReduce jobs are submitted to Hadoop in a sorted order. Finally, these MapReduce jobs are executed on Hadoop producing the desired results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pig Latin Data Model\n",
    "---\n",
    "The data model of Pig Latin is fully nested and it allows complex non-atomic datatypes such as map and tuple. Given below is the diagrammatical representation of Pig Latin’s data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](files/data_model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Atom</b><br>\n",
    "Any single value in Pig Latin, irrespective of their data, type is known as an Atom. It is stored as string and can be used as string and number. int, long, float, double, chararray, and bytearray are the atomic values of Pig. A piece of data or a simple atomic value is known as a field.\n",
    "\n",
    "Example − ‘raja’ or ‘30’\n",
    "\n",
    "<b>Tuple</b><br>\n",
    "A record that is formed by an ordered set of fields is known as a tuple, the fields can be of any type. A tuple is similar to a row in a table of RDBMS.\n",
    "\n",
    "Example − (Raja, 30)\n",
    "\n",
    "<b>Bag</b><br>\n",
    "A bag is an unordered set of tuples. In other words, a collection of tuples (non-unique) is known as a bag. Each tuple can have any number of fields (flexible schema). A bag is represented by ‘{}’. It is similar to a table in RDBMS, but unlike a table in RDBMS, it is not necessary that every tuple contain the same number of fields or that the fields in the same position (column) have the same type.\n",
    "\n",
    "Example − {(Raja, 30), (Mohammad, 45)}\n",
    "\n",
    "A bag can be a field in a relation; in that context, it is known as inner bag.\n",
    "\n",
    "Example − {Raja, 30, {9848022338, raja@gmail.com,}}\n",
    "\n",
    "<b>Map</b><br>\n",
    "A map (or data map) is a set of key-value pairs. The key needs to be of type chararray and should be unique. The value might be of any type. It is represented by ‘[]’\n",
    "\n",
    "Example − [name#Raja, age#30]\n",
    "\n",
    "<b>Relation</b><br>\n",
    "A relation is a bag of tuples. The relations in Pig Latin are unordered (there is no guarantee that tuples are processed in any particular order)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Exercises\n",
    "---\n",
    "\n",
    "1. [Installation](http://localhost:8888/notebooks/Globe/execution/pig/01.ipynb)\n",
    "2. [Execution](http://localhost:8888/notebooks/Globe/execution/pig/02.ipynb)\n",
    "1. [Grunt Shell](http://localhost:8888/notebooks/Globe/execution/pig/03.ipynb)\n",
    "2. [Pig Latin](http://localhost:8888/notebooks/Globe/execution/pig/04.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
